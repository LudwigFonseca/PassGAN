{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PassGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is mainly for debugging, has same functionality to \"train.py\". However, the parameters are configured small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv1d\n",
    "import tflib.plot\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:55:05.750119: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.750176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3050 Ti Laptop GPU major: 8 minor: 6 memoryClockRate(GHz): 1.485\n",
      "pciBusID: 0000:01:00.0\n",
      "2024-03-16 23:55:05.750214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-03-16 23:55:05.750220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-03-16 23:55:05.750228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-03-16 23:55:05.750233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-03-16 23:55:05.750252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-03-16 23:55:05.750256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-03-16 23:55:05.750261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-16 23:55:05.750529: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.750905: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.750938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2024-03-16 23:55:05.750995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-03-16 23:55:05.751001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2024-03-16 23:55:05.751005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2024-03-16 23:55:05.751656: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.751710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1387] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-16 23:55:05.752062: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.752125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 2989 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2024-03-16 23:55:05.753775: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.753855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3050 Ti Laptop GPU major: 8 minor: 6 memoryClockRate(GHz): 1.485\n",
      "pciBusID: 0000:01:00.0\n",
      "2024-03-16 23:55:05.753917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-03-16 23:55:05.753981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-03-16 23:55:05.753990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-03-16 23:55:05.753998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-03-16 23:55:05.754005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-03-16 23:55:05.754011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-03-16 23:55:05.754020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-16 23:55:05.754312: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.754734: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:55:05.754748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow virsion\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify migration process between Jupyter Notebook and .py format, we created virtual ArgumentParser class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_ascii(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    filtered_content = ''.join(char for char in content if ord(char) < 128)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(filtered_content)\n",
    "\n",
    "input_file = \"data/Scrapy_Passwords.txt\"\n",
    "output_file = \"data/Scrapy_Passwords_cleaned.txt\"\n",
    "\n",
    "filter_non_ascii(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of characters in a line is: 105\n"
     ]
    }
   ],
   "source": [
    "def max_line_length(file_path):\n",
    "    max_length = 0\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_length = len(line.strip())\n",
    "            max_length = max(max_length, line_length)\n",
    "\n",
    "    return max_length\n",
    "\n",
    "file_path = \"data/Scrapy_Passwords.txt\"\n",
    "max_length = max_line_length(file_path)\n",
    "print(f\"The maximum number of characters in a line is: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to virtualize ArgumentParser\n",
    "class VirtualArgparse:\n",
    "    \n",
    "    # Path to dataset\n",
    "    training_data = \"data/Scrapy_Passwords_cleaned.txt\"\n",
    "    \n",
    "    # Name of directory to output\n",
    "    output_dir = \"scrapy\"\n",
    "    \n",
    "    save_every = 100   #5000\n",
    "    iters = 1000   #200000\n",
    "    batch_size = 64\n",
    "    seq_length = 25\n",
    "    layer_dim = 128\n",
    "    critic_iters = 10\n",
    "    lamb = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtualize ArgumentParser instance\n",
    "args = VirtualArgparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "if not os.path.isdir(os.path.join(args.output_dir, 'checkpoints')):\n",
    "    os.makedirs(os.path.join(args.output_dir, 'checkpoints'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(args.output_dir, 'samples')):\n",
    "    os.makedirs(os.path.join(args.output_dir, 'samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Scrapy_Passwords_cleaned.txt\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(args.training_data)\n",
    "print(args.seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 56498 lines in dataset\n"
     ]
    }
   ],
   "source": [
    "lines, charmap, inv_charmap = utils.load_dataset(\n",
    "    path=args.training_data,\n",
    "    max_length=args.seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in dataset: 96\n"
     ]
    }
   ],
   "source": [
    "# Pickle to avoid encoding errors with json\n",
    "with open(os.path.join(args.output_dir, 'charmap.pickle'), 'wb') as f:\n",
    "    pickle.dump(charmap, f)\n",
    "\n",
    "with open(os.path.join(args.output_dir, 'charmap_inv.pickle'), 'wb') as f:\n",
    "    pickle.dump(inv_charmap, f)\n",
    "    \n",
    "print(\"Number of unique characters in dataset: {}\".format(len(charmap)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 25, 96)\n"
     ]
    }
   ],
   "source": [
    "# Define the placeholder using tf.keras.Input()\n",
    "real_inputs_discrete = tf.keras.Input(shape=[args.batch_size, args.seq_length], dtype=tf.int32)\n",
    "\n",
    "# Convert discrete inputs to one-hot encoding using TensorFlow operation\n",
    "real_inputs = tf.one_hot(real_inputs_discrete, len(charmap))\n",
    "\n",
    "# Print the shape of the one-hot encoded inputs\n",
    "print(real_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29281/23999606.py:1: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "real_inputs_discrete = tf.placeholder(tf.int32, shape=[args.batch_size, args.seq_length])\n",
    "real_inputs = tf.one_hot(real_inputs_discrete, len(charmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(64, 25), dtype=int32)\n",
      "Tensor(\"one_hot_1:0\", shape=(64, 25, 96), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(real_inputs_discrete)\n",
    "print(real_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/d/Projetos/OwnProjects/BruteForce/PassGAN/models.py:54: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_inputs = models.Generator(args.batch_size, args.seq_length, args.layer_dim, len(charmap))\n",
    "fake_inputs_discrete = tf.argmax(fake_inputs, fake_inputs.get_shape().ndims-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_real = models.Discriminator(real_inputs, args.seq_length, args.layer_dim, len(charmap))\n",
    "disc_fake = models.Discriminator(fake_inputs, args.seq_length, args.layer_dim, len(charmap))\n",
    "\n",
    "disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "gen_cost = -tf.reduce_mean(disc_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29281/3471863018.py:2: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_29281/3471863018.py:18: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# WGAN lipschitz-penalty\n",
    "alpha = tf.random_uniform(\n",
    "    shape=[args.batch_size,1,1],\n",
    "    minval=0.,\n",
    "    maxval=1.\n",
    ")\n",
    "\n",
    "differences = fake_inputs - real_inputs\n",
    "interpolates = real_inputs + (alpha*differences)\n",
    "gradients = tf.gradients(models.Discriminator(interpolates, args.seq_length, args.layer_dim, len(charmap)), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1,2]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "disc_cost += args.lamb * gradient_penalty\n",
    "\n",
    "gen_params = lib.params_with_name('Generator')\n",
    "disc_params = lib.params_with_name('Discriminator')\n",
    "\n",
    "gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(gen_cost, var_list=gen_params)\n",
    "disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(disc_cost, var_list=disc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset iterator\n",
    "def inf_train_gen():\n",
    "    while True:\n",
    "        np.random.shuffle(lines)\n",
    "        for i in range(0, len(lines)-args.batch_size+1, args.batch_size):\n",
    "            yield np.array(\n",
    "                [[charmap[c] for c in l] for l in lines[i:i+args.batch_size]],\n",
    "                dtype='int32'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set JSD for n=1: 0.0012527983135280426\n",
      "validation set JSD for n=2: 0.010837599210729803\n",
      "validation set JSD for n=3: 0.054586084631164565\n",
      "validation set JSD for n=4: 0.1342479767039421\n"
     ]
    }
   ],
   "source": [
    "# During training we monitor JS divergence between the true & generated ngram\n",
    "# distributions for n=1,2,3,4. To get an idea of the optimal values, we\n",
    "# evaluate these statistics on a held-out set first.\n",
    "true_char_ngram_lms = [utils.NgramLanguageModel(i+1, lines[10*args.batch_size:], tokenize=False) for i in range(4)]\n",
    "validation_char_ngram_lms = [utils.NgramLanguageModel(i+1, lines[:10*args.batch_size], tokenize=False) for i in range(4)]\n",
    "for i in range(4):\n",
    "    print(\"validation set JSD for n={}: {}\".format(i+1, true_char_ngram_lms[i].js_with(validation_char_ngram_lms[i])))\n",
    "true_char_ngram_lms = [utils.NgramLanguageModel(i+1, lines, tokenize=False) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29281/1180654942.py:1: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Starting TensorFlow session...\n",
      "Local current time : Sat Mar 16 23:57:09 2024\n",
      "WARNING:tensorflow:From /tmp/ipykernel_29281/1180654942.py:9: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:57:09.760380: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:57:09.760461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3050 Ti Laptop GPU major: 8 minor: 6 memoryClockRate(GHz): 1.485\n",
      "pciBusID: 0000:01:00.0\n",
      "2024-03-16 23:57:09.760585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-03-16 23:57:09.760594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-03-16 23:57:09.760602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-03-16 23:57:09.760607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-03-16 23:57:09.760628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-03-16 23:57:09.760632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-03-16 23:57:09.760638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-16 23:57:09.760895: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:57:09.761238: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:57:09.761297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2024-03-16 23:57:09.761358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-03-16 23:57:09.761380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2024-03-16 23:57:09.761386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2024-03-16 23:57:09.761846: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:57:09.761900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1387] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-16 23:57:09.762231: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 23:57:09.762330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2989 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2024-03-17 00:02:29.877973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-03-17 00:03:45.389064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-17 00:18:44.785854: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.3.1 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-03-17 00:18:44.786865: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.3.1 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-03-17 00:18:44.789732: E tensorflow/stream_executor/cuda/cuda_blas.cc:428] failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Discriminator.Input/conv1d (defined at home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[add_21/_3]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Discriminator.Input/conv1d (defined at home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Discriminator.Input/conv1d':\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n    app.start()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n    return runner(coro)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_29281/614861853.py\", line 1, in <module>\n    disc_real = models.Discriminator(real_inputs, args.seq_length, args.layer_dim, len(charmap))\n  File \"mnt/d/Projetos/OwnProjects/BruteForce/PassGAN/models.py\", line 35, in Discriminator\n    output = lib.ops.conv1d.Conv1D('Discriminator.Input', input_dim, layer_dim, 1, output)\n  File \"mnt/d/Projetos/OwnProjects/BruteForce/PassGAN/tflib/ops/conv1d.py\", line 92, in Conv1D\n    padding='SAME'\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 574, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 574, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1681, in conv1d\n    name=name)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node Discriminator.Input/conv1d}}]]\n\t [[add_21/_3]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node Discriminator.Input/conv1d}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29281/1180654942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             _disc_cost, _ = session.run(\n\u001b[1;32m     35\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mdisc_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_train_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_inputs_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Discriminator.Input/conv1d (defined at home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[add_21/_3]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Discriminator.Input/conv1d (defined at home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Discriminator.Input/conv1d':\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n    app.start()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n    return runner(coro)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_29281/614861853.py\", line 1, in <module>\n    disc_real = models.Discriminator(real_inputs, args.seq_length, args.layer_dim, len(charmap))\n  File \"mnt/d/Projetos/OwnProjects/BruteForce/PassGAN/models.py\", line 35, in Discriminator\n    output = lib.ops.conv1d.Conv1D('Discriminator.Input', input_dim, layer_dim, 1, output)\n  File \"mnt/d/Projetos/OwnProjects/BruteForce/PassGAN/tflib/ops/conv1d.py\", line 92, in Conv1D\n    padding='SAME'\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 574, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 574, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1681, in conv1d\n    name=name)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"home/jarvis/miniconda3/envs/PassGAN/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "\n",
    "    # Time stamp\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print(\"Starting TensorFlow session...\")\n",
    "    print(\"Local current time :\", localtime)\n",
    "    \n",
    "    # Start TensorFlow session...\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def generate_samples():\n",
    "        samples = session.run(fake_inputs)\n",
    "        samples = np.argmax(samples, axis=2)\n",
    "        decoded_samples = []\n",
    "        for i in range(len(samples)):\n",
    "            decoded = []\n",
    "            for j in range(len(samples[i])):\n",
    "                decoded.append(inv_charmap[samples[i][j]])\n",
    "            decoded_samples.append(tuple(decoded))\n",
    "        return decoded_samples\n",
    "\n",
    "    gen = inf_train_gen()\n",
    "\n",
    "    for iteration in range(args.iters + 1):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train Generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(gen_train_op)\n",
    "\n",
    "        # Train Discriminator\n",
    "        for i in range(args.critic_iters):\n",
    "            _data = next(gen)\n",
    "            _disc_cost, _ = session.run(\n",
    "                [disc_cost, disc_train_op],\n",
    "                feed_dict={real_inputs_discrete:_data}\n",
    "            )\n",
    "\n",
    "        lib.plot.output_dir = args.output_dir\n",
    "        lib.plot.plot('time', time.time() - start_time)\n",
    "        lib.plot.plot('train disc cost', _disc_cost)\n",
    "\n",
    "        # Output to text file after every 100 samples\n",
    "        if iteration % 100 == 0 and iteration > 0:\n",
    "\n",
    "            samples = []\n",
    "            for i in range(10):\n",
    "                samples.extend(generate_samples())\n",
    "\n",
    "            for i in range(4):\n",
    "                lm = utils.NgramLanguageModel(i+1, samples, tokenize=False)\n",
    "                lib.plot.plot('js{}'.format(i+1), lm.js_with(true_char_ngram_lms[i]))\n",
    "\n",
    "            with open(os.path.join(args.output_dir, 'samples', 'samples_{}.txt').format(iteration), 'w') as f:\n",
    "                for s in samples:\n",
    "                    s = \"\".join(s)\n",
    "                    f.write(s + \"\\n\")\n",
    "\n",
    "        if iteration % args.save_every == 0 and iteration > 0:\n",
    "            model_saver = tf.train.Saver()\n",
    "            model_saver.save(session, os.path.join(args.output_dir, 'checkpoints', 'checkpoint_{}.ckpt').format(iteration))\n",
    "            print(\"{} / {} ({}%)\".format(iteration, args.iters, iteration/args.iters*100.0 ))\n",
    "\n",
    "        if iteration == args.iters:\n",
    "            print(\"...Training done.\")\n",
    "        \n",
    "        #if iteration % 100 == 0:\n",
    "            #lib.plot.flush()\n",
    "\n",
    "        #lib.plot.tick()\n",
    "        \n",
    "# Time stamp\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Ending TensorFlow session.\")\n",
    "print(\"Local current time :\", localtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
